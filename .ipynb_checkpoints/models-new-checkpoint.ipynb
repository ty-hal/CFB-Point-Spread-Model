{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf236e5a-6c5d-4f75-911b-a4ee565f5111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tyhal\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, learning_curve, cross_val_score, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import random\n",
    "import plotly.express as px\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Range of years\n",
    "start_year = 2013\n",
    "end_year = 2022\n",
    "current_year = 2023\n",
    "\n",
    "# Set environment variables for reproducibility\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c7c06e-3f14-4df9-9fb3-6e4f42558cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5372, 311)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataframe\n",
    "with open('data.pickle','rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23647782-4834-4e2f-8b4a-a03551a7d4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<xgboost.core.Booster at 0x228fa794710>,\n",
       " <xgboost.core.Booster at 0x228fa794810>,\n",
       " <xgboost.core.Booster at 0x228fa794c50>,\n",
       " <xgboost.core.Booster at 0x228fa794e50>,\n",
       " <xgboost.core.Booster at 0x228fa795110>,\n",
       " <xgboost.core.Booster at 0x228fa795410>,\n",
       " <xgboost.core.Booster at 0x228fa795650>,\n",
       " <xgboost.core.Booster at 0x228fa794690>,\n",
       " <xgboost.core.Booster at 0x228bd63dc50>,\n",
       " <xgboost.core.Booster at 0x228fa796010>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i, model in enumerate(xgb_model):\n",
    "#     with open(f'xgb_model_{i}.pkl', 'wb') as f:\n",
    "#         pickle.dump(model, f)\n",
    "\n",
    "xgb_model = []\n",
    "for i in range(10):\n",
    "    with open(f'xgb_model_{i}.pkl', 'rb') as f:\n",
    "        temp_xgb_model = pickle.load(f)\n",
    "        xgb_model.append(temp_xgb_model)\n",
    "xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2900e2ba-3668-4dd7-99af-d89bfe433491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost model config\n",
    "def cauchyobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    c = 5000 \n",
    "    x =  preds-labels    \n",
    "    grad = x / (x**2/c**2+1)\n",
    "    hess = -c**2*(x**2-c**2)/(x**2+c**2)**2\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "param = {} \n",
    "\n",
    "# Testing:\n",
    "param['eval_metric'] =  'mae'\n",
    "param['booster'] = 'gbtree'\n",
    "param['eta'] = 0.05 #change to ~0.02 for final run (from 0.05)\n",
    "param['subsample'] = 0.35\n",
    "param['colsample_bytree'] = 0.7\n",
    "param['num_parallel_tree'] = 3 #recommend 10 (from 3)\n",
    "param['min_child_weight'] = 40 \n",
    "param['gamma'] = 10\n",
    "param['max_depth'] =  3\n",
    "# param['silent'] = 1\n",
    "repeat_cv = 3 # recommend 10 (from 3)\n",
    "\n",
    "\n",
    "# Submission:\n",
    "# param['eval_metric'] =  'mae'\n",
    "# param['booster'] = 'gbtree'\n",
    "# param['eta'] = 0.02 #change to ~0.02 for final run (from 0.05)\n",
    "# param['subsample'] = 0.35\n",
    "# param['colsample_bytree'] = 0.7\n",
    "# param['num_parallel_tree'] = 10 #recommend 10 (from 3)\n",
    "# param['min_child_weight'] = 40 \n",
    "# param['gamma'] = 10\n",
    "# param['max_depth'] =  3\n",
    "# # param['silent'] = 1\n",
    "# repeat_cv = 10 # recommend 10 (from 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f2471f8-84b2-4cd7-a947-881460791ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(dtrain):\n",
    "    xgb_cv = []\n",
    "\n",
    "    for i in range(repeat_cv): \n",
    "        print(f\"Fold repeater {i}\")\n",
    "        xgb_cv.append(\n",
    "            xgb.cv(\n",
    "              params = param,\n",
    "              dtrain = dtrain,\n",
    "              obj = cauchyobj,\n",
    "              num_boost_round = 3000,\n",
    "              folds = KFold(n_splits = 5, shuffle = True, random_state = i),\n",
    "              early_stopping_rounds = 25,\n",
    "              verbose_eval = 50\n",
    "            )\n",
    "        )\n",
    "\n",
    "    iteration_counts = [np.argmin(x['test-mae-mean'].values) for x in xgb_cv]\n",
    "    val_mae = [np.min(x['test-mae-mean'].values) for x in xgb_cv]\n",
    "    print(iteration_counts, val_mae, \"\\n\\n\")\n",
    "    return xgb_cv, iteration_counts\n",
    "\n",
    "def oof_predictions(X, y, iteration_counts):\n",
    "    oof_preds = []\n",
    "    for i in range(repeat_cv):\n",
    "        print(f\"Fold repeater {i}\")\n",
    "        preds = y.copy()\n",
    "        kfold = KFold(n_splits = 5, shuffle = True, random_state = i)    \n",
    "        for train_index, val_index in kfold.split(X,y):\n",
    "            dtrain_i = xgb.DMatrix(X[train_index], label = y[train_index])\n",
    "            dval_i = xgb.DMatrix(X[val_index], label = y[val_index])  \n",
    "            model = xgb.train(\n",
    "                  params = param,\n",
    "                  dtrain = dtrain_i,\n",
    "                  num_boost_round = iteration_counts[i],\n",
    "                  verbose_eval = 50\n",
    "            )\n",
    "            preds[val_index] = model.predict(dval_i)\n",
    "        oof_preds.append(np.clip(preds,-30,30))\n",
    "    print(\"MAE: \", mean_absolute_error(sum(oof_preds)/len(oof_preds), y), \"\\n\\n\")\n",
    "    return oof_preds\n",
    "\n",
    "def train_final_model(dtrain, iteration_counts):\n",
    "    xgboost_models = []\n",
    "    for i in range(repeat_cv):\n",
    "        print(f\"Fold repeater {i}\")\n",
    "        xgboost_models.append(\n",
    "            xgb.train(\n",
    "              params = param,\n",
    "              dtrain = dtrain,\n",
    "              num_boost_round = int(iteration_counts[i] * 1.05),\n",
    "              verbose_eval = 50\n",
    "            )\n",
    "        )\n",
    "    return xgboost_models\n",
    "\n",
    "def prediction(xgboost_models, dmatrix):\n",
    "    preds = []\n",
    "    for i in range(repeat_cv):\n",
    "        preds.append(np.clip(xgboost_models[i].predict(dmatrix),-300,300))\n",
    "    return sum(preds) / len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e57a66c-027e-4712-ac01-1a8422a43260",
   "metadata": {},
   "source": [
    "# Final data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06d91797-dee1-4677-a3c7-8f46f13998d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = ['id','year','week','home_team','away_team','margin','home_points','away_points']\n",
    "categorical_features = ['neutral_site', 'home_conference','away_conference']\n",
    "cont_features = [c for c in data.columns.to_list() if c not in categorical_features and c not in excluded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c010b77-c13d-42c1-895f-74c41c54dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.query(\"year >= 2022\")\n",
    "train_data = data.query(\"year < 2022\")\n",
    "# test_data = data.query(\"year >= 2022 and week >= 3\")\n",
    "# train_data = data.query(\"year < 2022 and week >= 3\")\n",
    "\n",
    "vegas_rmse = mean_squared_error(test_data['spread'], test_data['margin']) ** 0.5\n",
    "vegas_mae = mean_absolute_error(test_data['spread'], test_data['margin'])\n",
    "\n",
    "X_train = train_data.drop(columns=excluded)\n",
    "X_test = test_data.drop(columns=excluded)\n",
    "\n",
    "y_train = train_data['margin'].values\n",
    "y_test = test_data['margin'].values\n",
    "\n",
    "quantitative_features = [item for item in list(X_train.columns) if item not in categorical_features]\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse=False, drop='first', handle_unknown='ignore'), categorical_features),  # One-hot encode categorical features\n",
    "        ('num', StandardScaler(), quantitative_features),  # Standardize numerical features\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through any features not explicitly transformed\n",
    ")\n",
    "\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "dtrain = xgb.DMatrix(X_train_scaled, label = y_train)\n",
    "dtest = xgb.DMatrix(X_test_scaled, label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab80493c-a896-48fe-9a6a-c7c1eda0a993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold repeater 0\n",
      "[0]\ttrain-mae:17.04491+0.11134\ttest-mae:17.06063+0.44327\n",
      "[50]\ttrain-mae:12.20497+0.08289\ttest-mae:12.72942+0.30085\n",
      "[100]\ttrain-mae:11.69248+0.08695\ttest-mae:12.67087+0.29834\n",
      "[110]\ttrain-mae:11.61282+0.08706\ttest-mae:12.67100+0.28830\n",
      "Fold repeater 1\n",
      "[0]\ttrain-mae:17.05738+0.15441\ttest-mae:17.06974+0.62948\n",
      "[50]\ttrain-mae:12.20524+0.05594\ttest-mae:12.75692+0.28633\n",
      "[100]\ttrain-mae:11.69498+0.05973\ttest-mae:12.66431+0.25190\n",
      "[115]\ttrain-mae:11.56850+0.06232\ttest-mae:12.66832+0.25563\n",
      "Fold repeater 2\n",
      "[0]\ttrain-mae:17.05541+0.06116\ttest-mae:17.07231+0.27077\n",
      "[50]\ttrain-mae:12.21178+0.08179\ttest-mae:12.71482+0.31756\n",
      "[100]\ttrain-mae:11.69557+0.07130\ttest-mae:12.65424+0.31146\n",
      "[132]\ttrain-mae:11.44249+0.07144\ttest-mae:12.66157+0.31384\n",
      "[85, 90, 108] [12.664752544895295, 12.663577090553058, 12.651185437312689] \n",
      "\n",
      "\n",
      "Fold repeater 0\n",
      "Fold repeater 1\n",
      "Fold repeater 2\n",
      "MAE:  12.673763440860215 \n",
      "\n",
      "\n",
      "Fold repeater 0\n",
      "Fold repeater 1\n",
      "Fold repeater 2\n",
      "15.43997919392271 12.1873414578578\n"
     ]
    }
   ],
   "source": [
    "xgb_cv, iteration_counts = train_xgboost(dtrain)\n",
    "oof_preds = oof_predictions(X_train_scaled, y_train, iteration_counts)\n",
    "xgb_model = train_final_model(dtrain, iteration_counts)\n",
    "\n",
    "XGBprediction = prediction(xgb_model, dtest)\n",
    "print(\"RMSE: \", mean_squared_error(y_test, XGBprediction) ** 0.5, '  MAE: \", mean_absolute_error(y_test, XGBprediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b41256e-1960-4b92-9073-a673c3ea818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the difference of home and away features for each stat\n",
    "paired_columns = []\n",
    "nonpaired_columns = ['neutral_site', 'spread', 'home_conference', 'away_conference', 'home_team_performance_at_home_past_1_years', 'away_team_performance_at_away_past_1_years', 'home_team_performance_at_home_past_2_years', 'away_team_performance_at_away_past_2_years', 'home_team_performance_at_home_past_5_years', 'away_team_performance_at_away_past_5_years', 'home_vs_away_teams_performances_past_1_years', 'home_vs_away_teams_performances_past_2_years', 'home_vs_away_teams_performances_past_5_years']\n",
    "\n",
    "for column in list(X_train.columns):\n",
    "    if column in nonpaired_columns:\n",
    "        continue\n",
    "    if column.startswith(\"home_\"):\n",
    "        element = column[len(\"home_\"):]\n",
    "        if  element not in paired_columns:\n",
    "            paired_columns.append(element)\n",
    "    elif column.startswith(\"away_\"):\n",
    "        element = column[len(\"away_\"):]\n",
    "        if  element not in paired_columns:\n",
    "            paired_columns.append(element)\n",
    "    else:\n",
    "        nonpaired_columns.append(column)\n",
    "        \n",
    "paired_X_train = X_train[nonpaired_columns].copy()\n",
    "paired_X_test = X_test[nonpaired_columns].copy()\n",
    "combined_X_train = X_train.copy()\n",
    "combined_X_test = X_test.copy()\n",
    "\n",
    "for feature in paired_columns:\n",
    "    home_col = f'home_{feature}'\n",
    "    away_col = f'away_{feature}'\n",
    "    diff_col = f'diff_{feature}'\n",
    "    paired_X_train[diff_col] = X_train[home_col] - X_train[away_col]\n",
    "    paired_X_test[diff_col] = X_test[home_col] - X_test[away_col]\n",
    "    combined_X_train[diff_col] = X_train[home_col] - X_train[away_col]\n",
    "    combined_X_test[diff_col] = X_test[home_col] - X_test[away_col]\n",
    "    \n",
    "paired_quantitative_features = [item for item in list(paired_X_train.columns) if item not in categorical_features]\n",
    "combined_quantitative_features = [item for item in list(paired_X_train.columns) if item not in categorical_features]\n",
    "\n",
    "paired_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse=False, drop='first', handle_unknown='ignore'), categorical_features),  # One-hot encode categorical features\n",
    "        ('num', StandardScaler(), paired_quantitative_features),  # Standardize numerical features\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through any features not explicitly transformed\n",
    ")\n",
    "combined_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse=False, drop='first', handle_unknown='ignore'), categorical_features),  # One-hot encode categorical features\n",
    "        ('num', StandardScaler(), combined_quantitative_features),  # Standardize numerical features\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through any features not explicitly transformed\n",
    ")\n",
    "\n",
    "paired_X_train_scaled = paired_preprocessor.fit_transform(paired_X_train)\n",
    "paired_X_test_scaled = paired_preprocessor.transform(paired_X_test)\n",
    "combined_X_train_scaled = combined_preprocessor.fit_transform(combined_X_train)\n",
    "combined_X_test_scaled = combined_preprocessor.transform(combined_X_test)\n",
    "\n",
    "paired_dtrain = xgb.DMatrix(paired_X_train_scaled, label = y_train)\n",
    "paired_dtest = xgb.DMatrix(paired_X_test_scaled, label = y_test)\n",
    "combined_dtrain = xgb.DMatrix(combined_X_train_scaled, label = y_train)\n",
    "combined_dtest = xgb.DMatrix(combined_X_test_scaled, label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e861cc28-433b-47c6-8883-467f37849a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold repeater 0\n",
      "[0]\ttrain-mae:16.92039+0.10750\ttest-mae:16.92944+0.44725\n",
      "[50]\ttrain-mae:12.22946+0.07581\ttest-mae:12.66856+0.29492\n",
      "[100]\ttrain-mae:11.78545+0.07579\ttest-mae:12.62751+0.30503\n",
      "[101]\ttrain-mae:11.77807+0.07465\ttest-mae:12.62889+0.30518\n",
      "Fold repeater 1\n",
      "[0]\ttrain-mae:16.92418+0.15229\ttest-mae:16.93146+0.63005\n",
      "[50]\ttrain-mae:12.22715+0.06079\ttest-mae:12.70802+0.28303\n",
      "[100]\ttrain-mae:11.78260+0.06330\ttest-mae:12.66131+0.25306\n",
      "[115]\ttrain-mae:11.67500+0.06746\ttest-mae:12.66586+0.25189\n",
      "Fold repeater 2\n",
      "[0]\ttrain-mae:16.92013+0.05821\ttest-mae:16.92635+0.26224\n",
      "[50]\ttrain-mae:12.23212+0.07676\ttest-mae:12.70100+0.32555\n",
      "[100]\ttrain-mae:11.78096+0.06396\ttest-mae:12.65129+0.32118\n",
      "[110]\ttrain-mae:11.70994+0.06017\ttest-mae:12.66221+0.32345\n",
      "[76, 90, 85] [12.616417559385301, 12.656976708994119, 12.647527934646094] \n",
      "\n",
      "\n",
      "Fold repeater 0\n",
      "Fold repeater 1\n",
      "Fold repeater 2\n",
      "MAE:  12.676200716845878 \n",
      "\n",
      "\n",
      "Fold repeater 0\n",
      "Fold repeater 1\n",
      "Fold repeater 2\n",
      "RMSE:  15.38215857072253 MAE:  12.142550613084897\n"
     ]
    }
   ],
   "source": [
    "paired_xgb_cv, paired_iteration_counts = train_xgboost(paired_dtrain)\n",
    "oof_preds = oof_predictions(paired_X_train_scaled, y_train, paired_iteration_counts)\n",
    "paired_xgb_model = train_final_model(paired_dtrain, paired_iteration_counts)\n",
    "\n",
    "paired_xgb_prediction = prediction(paired_xgb_model, paired_dtest)\n",
    "print(\"RMSE: \", mean_squared_error(y_test, paired_xgb_prediction) ** 0.5,  \"MAE: \", mean_absolute_error(y_test, paired_xgb_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d59d6aed-3e29-4a55-b87d-ac4fd4d42810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold repeater 0\n",
      "[0]\ttrain-mae:16.95423+0.10825\ttest-mae:16.96706+0.44804\n",
      "[50]\ttrain-mae:12.16261+0.08268\ttest-mae:12.69525+0.31449\n",
      "[100]\ttrain-mae:11.64750+0.08156\ttest-mae:12.64547+0.31493\n",
      "[110]\ttrain-mae:11.56292+0.07931\ttest-mae:12.64330+0.31864\n",
      "Fold repeater 1\n",
      "[0]\ttrain-mae:16.96049+0.15080\ttest-mae:16.97320+0.62680\n",
      "[50]\ttrain-mae:12.15254+0.06256\ttest-mae:12.71664+0.27937\n",
      "[100]\ttrain-mae:11.63148+0.06264\ttest-mae:12.65373+0.23836\n",
      "[108]\ttrain-mae:11.55543+0.06278\ttest-mae:12.65161+0.23832\n",
      "Fold repeater 2\n",
      "[0]\ttrain-mae:16.95833+0.05814\ttest-mae:16.96827+0.26949\n",
      "[50]\ttrain-mae:12.16116+0.07714\ttest-mae:12.70770+0.35013\n",
      "[100]\ttrain-mae:11.63039+0.08285\ttest-mae:12.64925+0.32518\n",
      "[123]\ttrain-mae:11.43855+0.09023\ttest-mae:12.65365+0.31614\n",
      "[85, 84, 99] [12.635561412021678, 12.646657985102745, 12.649062271605256] \n",
      "\n",
      "\n",
      "Fold repeater 0\n",
      "Fold repeater 1\n",
      "Fold repeater 2\n",
      "MAE:  12.672544802867382 \n",
      "\n",
      "\n",
      "Fold repeater 0\n",
      "Fold repeater 1\n",
      "Fold repeater 2\n",
      "RMSE:  15.464552252717866 MAE:  12.20970734309178\n"
     ]
    }
   ],
   "source": [
    "combined_xgb_cv, combined_iteration_counts = train_xgboost(combined_dtrain)\n",
    "oof_preds = oof_predictions(combined_X_train_scaled, y_train, combined_iteration_counts)\n",
    "combined_xgb_model = train_final_model(combined_dtrain, combined_iteration_counts)\n",
    "\n",
    "combined_xgb_prediction = prediction(combined_xgb_model, combined_dtest)\n",
    "print(\"RMSE: \", mean_squared_error(y_test, combined_xgb_prediction) ** 0.5,  \"MAE: \", mean_absolute_error(y_test, combined_xgb_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b920926-24c7-44ee-862e-21392ad7110e",
   "metadata": {},
   "source": [
    "# Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0b636f73-640c-4ae1-a0ed-a9a3e29a11c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "        \n",
    "def train_neural_network(X_train, y_train, model_name=\"NNmodel.h5\"):\n",
    "    # Set environment variables for reproducibility\n",
    "    os.environ['PYTHONHASHSEED'] = str(42)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    random.seed(42)\n",
    "\n",
    "    lr_scheduler = LearningRateScheduler(schedule)\n",
    "    X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train_NN = X_train.astype('float32')\n",
    "    y_train_NN = y_train.astype('float32')\n",
    "    X_cv_NN = X_cv.astype('float32')\n",
    "    y_cv_NN = y_cv.astype('float32')\n",
    "\n",
    "    checkpoint = ModelCheckpoint(model_name, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "    # Build the neural network model for regression\n",
    "    sequentialModel = Sequential([\n",
    "        Dense(512, input_dim=X_train_NN.shape[1], activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    sequentialModel.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "\n",
    "    # Train the model\n",
    "    history = sequentialModel.fit(X_train_NN, y_train_NN, epochs=30, batch_size=32, validation_data=(X_cv_NN, y_cv_NN), callbacks=[checkpoint, lr_scheduler], verbose=1)\n",
    "    neural_network_model = load_model(model_name)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    predictions = neural_network_model.predict(X_cv_NN).reshape(-1)\n",
    "\n",
    "    # Find the epoch with the best validation loss\n",
    "    best_epoch = history.history['val_loss'].index(min(history.history['val_loss'])) + 1\n",
    "    print(f\"\\nBest epoch: {best_epoch}\")\n",
    "    \n",
    "    # Evaluate the model's performance on the validation set\n",
    "    print(f\"RMSE of Neural Network on CV Data: {mean_squared_error(y_cv_NN, predictions)**0.5}\")\n",
    "    print(f\"MAE of Neural Network on CV Data: {mean_absolute_error(y_cv_NN, predictions)}\")\n",
    "    \n",
    "    # Plot the learning curve\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return neural_network_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e2bab711-b4ab-4cbc-a610-25e81062dccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "106/117 [==========================>...] - ETA: 0s - loss: 441.5900 - mean_absolute_error: 16.4911\n",
      "Epoch 1: val_loss improved from inf to 400.16162, saving model to NNmodel.h5\n",
      "117/117 [==============================] - 3s 7ms/step - loss: 432.8194 - mean_absolute_error: 16.3151 - val_loss: 400.1616 - val_mean_absolute_error: 15.7402 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "109/117 [==========================>...] - ETA: 0s - loss: 351.8425 - mean_absolute_error: 14.7478\n",
      "Epoch 2: val_loss improved from 400.16162 to 315.11823, saving model to NNmodel.h5\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 352.4632 - mean_absolute_error: 14.7440 - val_loss: 315.1182 - val_mean_absolute_error: 14.0932 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "109/117 [==========================>...] - ETA: 0s - loss: 318.2120 - mean_absolute_error: 14.1394\n",
      "Epoch 3: val_loss improved from 315.11823 to 290.46823, saving model to NNmodel.h5\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 314.8217 - mean_absolute_error: 14.0742 - val_loss: 290.4682 - val_mean_absolute_error: 13.4302 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "106/117 [==========================>...] - ETA: 0s - loss: 303.4376 - mean_absolute_error: 13.8576\n",
      "Epoch 4: val_loss did not improve from 290.46823\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 303.5622 - mean_absolute_error: 13.8460 - val_loss: 399.1333 - val_mean_absolute_error: 16.2446 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "108/117 [==========================>...] - ETA: 0s - loss: 299.8534 - mean_absolute_error: 13.7557\n",
      "Epoch 5: val_loss did not improve from 290.46823\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 299.9971 - mean_absolute_error: 13.7685 - val_loss: 519.8756 - val_mean_absolute_error: 18.2473 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "110/117 [===========================>..] - ETA: 0s - loss: 299.9105 - mean_absolute_error: 13.6912\n",
      "Epoch 6: val_loss did not improve from 290.46823\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 299.2983 - mean_absolute_error: 13.6847 - val_loss: 343.9088 - val_mean_absolute_error: 14.7062 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "109/117 [==========================>...] - ETA: 0s - loss: 294.1372 - mean_absolute_error: 13.5673\n",
      "Epoch 7: val_loss did not improve from 290.46823\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 292.9572 - mean_absolute_error: 13.5237 - val_loss: 291.0772 - val_mean_absolute_error: 13.5721 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "117/117 [==============================] - ETA: 0s - loss: 290.9285 - mean_absolute_error: 13.5026\n",
      "Epoch 8: val_loss did not improve from 290.46823\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 290.9285 - mean_absolute_error: 13.5026 - val_loss: 291.3117 - val_mean_absolute_error: 13.5095 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "108/117 [==========================>...] - ETA: 0s - loss: 290.7188 - mean_absolute_error: 13.4980\n",
      "Epoch 9: val_loss improved from 290.46823 to 287.96780, saving model to NNmodel.h5\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 288.5876 - mean_absolute_error: 13.4389 - val_loss: 287.9678 - val_mean_absolute_error: 13.4299 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "110/117 [===========================>..] - ETA: 0s - loss: 286.6481 - mean_absolute_error: 13.3443\n",
      "Epoch 10: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 288.6148 - mean_absolute_error: 13.4020 - val_loss: 295.1845 - val_mean_absolute_error: 13.6247 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "117/117 [==============================] - ETA: 0s - loss: 277.0078 - mean_absolute_error: 13.1846\n",
      "Epoch 11: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 277.0078 - mean_absolute_error: 13.1846 - val_loss: 329.3352 - val_mean_absolute_error: 14.3774 - lr: 9.0484e-04\n",
      "Epoch 12/30\n",
      "108/117 [==========================>...] - ETA: 0s - loss: 282.0660 - mean_absolute_error: 13.3109\n",
      "Epoch 12: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 283.5509 - mean_absolute_error: 13.3302 - val_loss: 371.0577 - val_mean_absolute_error: 15.2434 - lr: 8.1873e-04\n",
      "Epoch 13/30\n",
      "107/117 [==========================>...] - ETA: 0s - loss: 286.1732 - mean_absolute_error: 13.3931\n",
      "Epoch 13: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 286.1648 - mean_absolute_error: 13.3965 - val_loss: 371.4013 - val_mean_absolute_error: 15.3762 - lr: 7.4082e-04\n",
      "Epoch 14/30\n",
      "111/117 [===========================>..] - ETA: 0s - loss: 274.9100 - mean_absolute_error: 13.1564\n",
      "Epoch 14: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 278.0413 - mean_absolute_error: 13.2215 - val_loss: 330.5249 - val_mean_absolute_error: 14.3219 - lr: 6.7032e-04\n",
      "Epoch 15/30\n",
      "108/117 [==========================>...] - ETA: 0s - loss: 287.9963 - mean_absolute_error: 13.4609\n",
      "Epoch 15: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 285.9843 - mean_absolute_error: 13.4081 - val_loss: 313.3753 - val_mean_absolute_error: 13.8669 - lr: 6.0653e-04\n",
      "Epoch 16/30\n",
      "108/117 [==========================>...] - ETA: 0s - loss: 277.5714 - mean_absolute_error: 13.1772\n",
      "Epoch 16: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 277.7850 - mean_absolute_error: 13.1829 - val_loss: 311.2109 - val_mean_absolute_error: 13.5877 - lr: 5.4881e-04\n",
      "Epoch 17/30\n",
      "117/117 [==============================] - ETA: 0s - loss: 279.9850 - mean_absolute_error: 13.2618\n",
      "Epoch 17: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 279.9850 - mean_absolute_error: 13.2618 - val_loss: 307.9934 - val_mean_absolute_error: 13.6021 - lr: 4.9659e-04\n",
      "Epoch 18/30\n",
      "113/117 [===========================>..] - ETA: 0s - loss: 274.9934 - mean_absolute_error: 13.1810\n",
      "Epoch 18: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 275.6880 - mean_absolute_error: 13.2074 - val_loss: 332.2667 - val_mean_absolute_error: 14.1326 - lr: 4.4933e-04\n",
      "Epoch 19/30\n",
      "106/117 [==========================>...] - ETA: 0s - loss: 277.5888 - mean_absolute_error: 13.2070\n",
      "Epoch 19: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 277.2188 - mean_absolute_error: 13.1975 - val_loss: 322.0039 - val_mean_absolute_error: 13.8727 - lr: 4.0657e-04\n",
      "Epoch 20/30\n",
      "109/117 [==========================>...] - ETA: 0s - loss: 274.7162 - mean_absolute_error: 13.2057\n",
      "Epoch 20: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 276.5435 - mean_absolute_error: 13.2200 - val_loss: 324.2871 - val_mean_absolute_error: 13.8297 - lr: 3.6788e-04\n",
      "Epoch 21/30\n",
      "116/117 [============================>.] - ETA: 0s - loss: 280.8253 - mean_absolute_error: 13.2798\n",
      "Epoch 21: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 280.4514 - mean_absolute_error: 13.2717 - val_loss: 323.8195 - val_mean_absolute_error: 13.8821 - lr: 3.3287e-04\n",
      "Epoch 22/30\n",
      "108/117 [==========================>...] - ETA: 0s - loss: 272.4832 - mean_absolute_error: 13.0568\n",
      "Epoch 22: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 274.8212 - mean_absolute_error: 13.1099 - val_loss: 323.2475 - val_mean_absolute_error: 13.7911 - lr: 3.0119e-04\n",
      "Epoch 23/30\n",
      "108/117 [==========================>...] - ETA: 0s - loss: 281.4297 - mean_absolute_error: 13.2655\n",
      "Epoch 23: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 277.7185 - mean_absolute_error: 13.1934 - val_loss: 315.6715 - val_mean_absolute_error: 13.6265 - lr: 2.7253e-04\n",
      "Epoch 24/30\n",
      "117/117 [==============================] - ETA: 0s - loss: 266.3065 - mean_absolute_error: 12.9244\n",
      "Epoch 24: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 266.3065 - mean_absolute_error: 12.9244 - val_loss: 315.9916 - val_mean_absolute_error: 13.6100 - lr: 2.4660e-04\n",
      "Epoch 25/30\n",
      "106/117 [==========================>...] - ETA: 0s - loss: 275.1952 - mean_absolute_error: 13.1718\n",
      "Epoch 25: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 275.5915 - mean_absolute_error: 13.1660 - val_loss: 319.7038 - val_mean_absolute_error: 13.6691 - lr: 2.2313e-04\n",
      "Epoch 26/30\n",
      "108/117 [==========================>...] - ETA: 0s - loss: 277.1478 - mean_absolute_error: 13.1438\n",
      "Epoch 26: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 277.2010 - mean_absolute_error: 13.1434 - val_loss: 314.2591 - val_mean_absolute_error: 13.5899 - lr: 2.0190e-04\n",
      "Epoch 27/30\n",
      "106/117 [==========================>...] - ETA: 0s - loss: 270.9921 - mean_absolute_error: 13.0820\n",
      "Epoch 27: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 273.5476 - mean_absolute_error: 13.1139 - val_loss: 314.3268 - val_mean_absolute_error: 13.5750 - lr: 1.8268e-04\n",
      "Epoch 28/30\n",
      "114/117 [============================>.] - ETA: 0s - loss: 273.9828 - mean_absolute_error: 13.1084\n",
      "Epoch 28: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 273.6592 - mean_absolute_error: 13.0968 - val_loss: 318.3554 - val_mean_absolute_error: 13.6468 - lr: 1.6530e-04\n",
      "Epoch 29/30\n",
      "107/117 [==========================>...] - ETA: 0s - loss: 280.0064 - mean_absolute_error: 13.2932\n",
      "Epoch 29: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 278.2175 - mean_absolute_error: 13.2273 - val_loss: 313.7604 - val_mean_absolute_error: 13.5639 - lr: 1.4957e-04\n",
      "Epoch 30/30\n",
      "117/117 [==============================] - ETA: 0s - loss: 271.9143 - mean_absolute_error: 13.0922\n",
      "Epoch 30: val_loss did not improve from 287.96780\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 271.9143 - mean_absolute_error: 13.0922 - val_loss: 311.7163 - val_mean_absolute_error: 13.5470 - lr: 1.3534e-04\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "\n",
      "Best epoch: 9\n",
      "RMSE of Neural Network on CV Data: 16.969614136894158\n",
      "MAE of Neural Network on CV Data: 13.429887771606445\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NNmodel = train_neural_network(combined_X_train_scaled, y_train, model_name=\"NNmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8b45dca6-663e-4399-bd3e-66f63981fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of the three models:\n",
    "# XGBmodel = xgb.XGBRegressor()\n",
    "# XGBmodel.load_model(\"XGBmodel.json\")\n",
    "# NNmodel = load_model('NNmodel.h5')\n",
    "\n",
    "class EnsembleModel:\n",
    "    def __init__(self, xgb_model, nn_model):\n",
    "        self.xgb_model = xgb_model\n",
    "        self.nn_model = nn_model\n",
    "\n",
    "    def predict(self, X):\n",
    "        xgb_prediction = prediction(self.xgb_model, xgb.DMatrix(X))\n",
    "        nn_prediction = self.nn_model.predict(X.astype('float32')).reshape(-1)\n",
    "        return (xgb_prediction + nn_prediction) / 2\n",
    "\n",
    "model = EnsembleModel(xgb_model=xgb_model, nn_model=NNmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aea1f94-603a-4c9f-b9a3-7f8dc6b22c38",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e68e4d6f-9920-4b7f-ae05-3ac9cb4edf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = ['Vegas Consensus Spread', 'XGBoost Regressor', 'Neural Network', 'Ensemble Model']\n",
    "# XGBprediction = prediction(xgb_model, xgb.DMatrix(X_test_scaled))\n",
    "# NNprediction = NNmodel.predict(X_test_scaled.astype('float32')).reshape(-1)\n",
    "# averagePrediction = model.predict(X_test_scaled)\n",
    "\n",
    "# rmse_values = [vegas_rmse,\n",
    "#               mean_squared_error(y_test, XGBprediction) ** 0.5,\n",
    "#               mean_squared_error(y_test, NNprediction) ** 0.5,\n",
    "#               mean_squared_error(y_test, averagePrediction) ** 0.5]\n",
    "# mae_values = [vegas_mae,\n",
    "#               mean_absolute_error(y_test, XGBprediction),\n",
    "#               mean_absolute_error(y_test, NNprediction),\n",
    "#               mean_absolute_error(y_test, averagePrediction)]\n",
    "# colors = ['skyblue', 'lightcoral', 'lightgreen', 'lightpink']\n",
    "\n",
    "# # Create a bar chart\n",
    "# plt.figure(figsize=(12, 5))\n",
    "# bars = plt.bar(model_names, rmse_values, color=colors)\n",
    "# plt.ylabel('Root Mean Squared Error (RMSE)')\n",
    "# plt.title('Comparison of RMSE between Vegas Consensus Spread and My Models')\n",
    "# plt.xticks(rotation=0)\n",
    "# plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "# # Add more space between the top of the bars and the outline of the chart\n",
    "# extra_space = 2 # Adjust this value to control the space\n",
    "# plt.ylim(top=max(rmse_values) + extra_space)\n",
    "\n",
    "# # Display the MAE values on top of the bars with a little offset\n",
    "# for bar, mae in zip(bars, rmse_values):\n",
    "#     plt.text(bar.get_x() + bar.get_width() / 2, mae + 0.005, str(round(mae, 4)),\n",
    "#              ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # Create a bar chart\n",
    "# plt.figure(figsize=(12, 5))\n",
    "# bars = plt.bar(model_names, mae_values, color=colors)\n",
    "# plt.ylabel('Mean Absolute Error (MAE)')\n",
    "# plt.title('Comparison of MAE between Vegas Consensus Spread and My Models')\n",
    "# plt.xticks(rotation=0)\n",
    "# plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "# plt.ylim(top=max(mae_values) + extra_space)\n",
    "\n",
    "# # Display the MAE values on top of the bars with a little offset\n",
    "# for bar, mae in zip(bars, mae_values):\n",
    "#     plt.text(bar.get_x() + bar.get_width() / 2, mae + 0.005, str(round(mae, 4)),\n",
    "#              ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22c170a-22f3-4212-a5c9-809d808621a1",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "656208af-4e04-4f78-903d-4e39730aa349",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_data(models, model_names, X, y):\n",
    "    \"\"\"\n",
    "    Scatter Plot of Actual vs. Predicted Margins: This function generates a scatter plot to visually compare the actual margins of victory with the \n",
    "    predicted margins produced by different machine learning models. The plot assists in assessing how well the models align with the true outcomes.\n",
    "\n",
    "    Parameters:\n",
    "    models: List of machine learning models to evaluate.\n",
    "    model_names: List of names corresponding to each model.\n",
    "    X: Feature data used for prediction.\n",
    "    y: True target variable values.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    for model, name in zip(models, model_names):\n",
    "        y_pred = model.predict(X)\n",
    "        plt.scatter(y, y_pred, alpha=0.5, label=name)\n",
    "\n",
    "    # Plot a diagonal red dashed line\n",
    "    plt.plot([min(y), max(y)], [min(y), max(y)], color='red', linestyle='--', lw=2)\n",
    "    plt.xlabel(\"Margin of victory (y_cv)\")\n",
    "    plt.ylabel(\"Predicted margin of victory (y_pred)\")\n",
    "    plt.title(\"Actual vs. Predicted Margin Values for Different Models\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "121e5c20-0263-48be-b158-8b3096b8c910",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_residuals(models, model_names, X, y):\n",
    "    \"\"\"\n",
    "    Residual Plot: This function creates a set of residual plots for evaluating the performance of multiple machine learning models. Residual plots \n",
    "    are useful for assessing how well the models' predictions align with the actual target variable values.\n",
    "    \n",
    "    Parameters:\n",
    "    models: List of machine learning models to evaluate.\n",
    "    model_names: List of names corresponding to each model.\n",
    "    X: Feature data.\n",
    "    y: Target variable data.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_models = len(models)\n",
    "    n_rows = 3\n",
    "    n_cols = n_models // n_rows + (n_models % n_rows > 0)\n",
    "    figsize = (15, 8)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "    fig.subplots_adjust(hspace=0.4)\n",
    "    \n",
    "    for i, (model, name) in enumerate(zip(models, model_names), 1):\n",
    "        ax = axes[i-1] if n_rows > 1 else axes\n",
    "        \n",
    "        y_pred = model.predict(X).ravel()\n",
    "        residuals = y.ravel() - y_pred\n",
    "        \n",
    "        ax.scatter(y_pred, residuals, alpha=0.5, label=name)\n",
    "        ax.axhline(y=0, color='red', linestyle='--', lw=2)  # Add a horizontal line at y=0\n",
    "        ax.set_xlabel(\"Predicted Values\")\n",
    "        ax.set_ylabel(\"Residuals\")\n",
    "        ax.set_title(f\"Residual Plot - {name}\")\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        \n",
    "        # Set x-axis and y-axis scales to be the same\n",
    "        min_val = min(y_pred.min(), residuals.min())\n",
    "        max_val = max(y_pred.max(), residuals.max())\n",
    "        ax.set_xlim(min_val, max_val)\n",
    "        ax.set_ylim(min_val, max_val)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d825ae7-23e8-4e5b-8133-e9c0ce2b20cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_distributions(models, model_names, X, y):\n",
    "    \"\"\"\n",
    "    Distribution Plot: This function generates a set of distribution plots for comparing the actual and predicted values from multiple machine learning models. \n",
    "    The plots showcase the distribution of values, providing insights into how well each model captures the underlying patterns in the data.\n",
    "    \n",
    "    Parameters:\n",
    "    models: List of machine learning models to evaluate.\n",
    "    model_names: List of names corresponding to each model.\n",
    "    X: Feature data.\n",
    "    y: Target variable data.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_models = len(models)\n",
    "    n_rows = 3\n",
    "    n_cols = n_models // n_rows + (n_models % n_rows > 0)\n",
    "    figsize = (15, 8)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "    fig.subplots_adjust(hspace=0.4)\n",
    "    \n",
    "    axes = axes.ravel()  # Flatten axes for easier indexing\n",
    "    \n",
    "    for i, (model, name) in enumerate(zip(models, model_names), 1):\n",
    "        ax = axes[i-1]\n",
    "        y_pred = model.predict(X).ravel()\n",
    "        \n",
    "        sns.kdeplot(y.ravel(), label=\"Actual\", fill=True, ax=ax)\n",
    "        sns.kdeplot(y_pred, label=f\"{name} Predicted\", fill=True, ax=ax)\n",
    "        ax.set_xlabel(\"Values\")\n",
    "        ax.set_ylabel(\"Density\")\n",
    "        ax.set_title(f\"Distribution Plot (Actual vs. {name} Predicted)\")\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcce91f0-bbc4-4789-b541-794c59231d32",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_feature_importances(model, column_names, n_features=100):\n",
    "    \"\"\"\n",
    "    Importance Score Plot: This plot represents the importance of each feature based on the number of times they are used for splitting across all \n",
    "    decision trees.\n",
    "\n",
    "    F-Score Plot: This plot represents the importance of each feature based on the \"weight,\" which is the number of times a feature appears in a \n",
    "    tree across all boosting rounds.\n",
    "\n",
    "    While both plots provide an indication of feature importance, they may not necessarily give the same ranking because they focus on different \n",
    "    aspects of the boosting process. The Importance Score is based on the number of times a feature is used for splitting, while the F-Score \n",
    "    considers the number of times a feature appears across all boosting rounds.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: XGBoost machine learning model to evaluate.\n",
    "    - column_names: Column names.\n",
    "    - n_features: How many features to plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Importance Score Plot\n",
    "    importance_scores = model.feature_importances_\n",
    "    feature_importances = pd.DataFrame({'Feature': column_names, 'Importance': importance_scores})\n",
    "    feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "    top_features = feature_importances.head(n_features)\n",
    "    top_features = top_features[::-1]\n",
    "\n",
    "    plt.figure(figsize=(10, min(n_features, 24)))\n",
    "    plt.barh(top_features['Feature'], top_features['Importance'])\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title(f'XGBoost Regressor: Importance Score Plot')\n",
    "    plt.show()\n",
    "\n",
    "    # F-Score Plot\n",
    "    weights = model.get_booster().get_fscore()  \n",
    "    weights_with_names = {column_names[int(key[1:])]: value for key, value in weights.items()}\n",
    "    sorted_weights = sorted(weights_with_names.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_features_by_weight = dict(sorted_weights[:n_features])\n",
    "    \n",
    "    plt.figure(figsize=(10, min(n_features, 24)))\n",
    "    plt.barh(list(top_features_by_weight.keys())[::-1], list(top_features_by_weight.values())[::-1])\n",
    "    plt.xlabel('F-Score')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title(f'XGBoost Regressor: F-Score Plot')\n",
    "    plt.show()\n",
    "\n",
    "    # Combine and average the importance scores\n",
    "    averaged_importances = {}\n",
    "    zero_importance_features = []\n",
    "\n",
    "    for column in column_names:\n",
    "        importance = (importance_scores[column_names == column].sum() +\n",
    "                      weights_with_names.get(column, 0)) / 2.0\n",
    "        averaged_importances[column] = importance\n",
    "        if importance < 0.01:\n",
    "            zero_importance_features.append(column)\n",
    "    n_most_important_features = sorted(averaged_importances, key=averaged_importances.get, reverse=True)[:n_features]\n",
    "    \n",
    "    return n_most_important_features, zero_importance_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31e70d0f-b81a-4c90-a63b-6a62f656ee5d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_heatmap(X):\n",
    "    \"\"\"\n",
    "    Error Heatmap: This function generates a heatmap to visualize the correlation matrix of features, helping to identify feature interactions affecting the model.\n",
    "\n",
    "    Parameters:\n",
    "    - X: DataFrame containing the features.\n",
    "    \"\"\"\n",
    "\n",
    "    fig = px.imshow(X.corr(), x=X.columns, y=X.columns)\n",
    "    \n",
    "    # Customize hover information\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(tickvals=list(range(len(X.columns))), ticktext=X.columns),\n",
    "        yaxis=dict(tickvals=list(range(len(X.columns))), ticktext=X.columns),\n",
    "        hovermode=\"closest\",\n",
    "    )\n",
    "    \n",
    "    fig.update_traces(hoverinfo=\"all\", hovertemplate=\"Feature 1: %{y}<br>Feature 2: %{x}<br>Correlation: %{z}\")\n",
    "    fig.update_layout(coloraxis_colorscale='viridis')\n",
    "    \n",
    "    # Adjust figure size and title\n",
    "    fig.update_layout(\n",
    "        width=1200,  # Adjust the width as needed\n",
    "        height=1200,  # Adjust the height as needed\n",
    "        title_text=\"Error Heatmap for Top Features\",\n",
    "    )\n",
    "    \n",
    "    # Adjust font size and rotation\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(tickangle=-90, tickfont=dict(size=10)),\n",
    "        yaxis=dict(tickfont=dict(size=10)),\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57a807ec-d7a5-4f41-abef-1481a22dd69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [XGBmodel, NNmodel, model]\n",
    "model_names = ['XGBoost Regressor', 'Neural Network', 'Ensemble Model']\n",
    "column_names = preprocessor.get_feature_names_out(input_features=X_train.columns)\n",
    "X_cv_scaled_with_column_names = pd.DataFrame(X_cv_scaled, columns=column_names)\n",
    "\n",
    "# plot_data(models, model_names, X_cv_scaled, y_cv)\n",
    "# plot_residuals(models, model_names, X_cv_scaled, y_cv)\n",
    "# plot_distributions(models, model_names, X_cv_scaled, y_cv)\n",
    "# n_most_important_features, zero_importance_features = get_feature_importances(XGBmodel, column_names, 100)\n",
    "# plot_heatmap(X_cv_scaled_with_column_names[n_most_important_features])\n",
    "\n",
    "# X_cv_important_features = pd.DataFrame(X_cv_scaled, columns=column_names)\n",
    "# X_cv_important_features = X_cv_important_features[n_most_important_features].values\n",
    "# X_train_important_features = pd.DataFrame(X_train_scaled, columns=column_names)\n",
    "# X_train_important_features = X_train_important_features[n_most_important_features].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc569d96-05d6-44ba-b69e-871b5ef9a1db",
   "metadata": {},
   "source": [
    "# Run the model(s) on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3f56a69b-8bd5-44fe-aed5-bfd2bcb868cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of Model on test data: 15.43997919392271\n",
      "RMSE of Vegas on test data: 15.27575478366049\n",
      "MAE of Model on test data: 12.1873414578578\n",
      "MAE of Vegas on test data: 12.011772853185596\n",
      "\n",
      "Results by difference between model and Vegas:\n",
      "|model-vegas| >= 0: win 48.61% out of 722 games, profit -51.91 units\n",
      "|model-vegas| >= 1: win 47.95% out of 488 games, profit -41.27 units\n",
      "|model-vegas| >= 2: win 48.35% out of 273 games, profit -21.00 units\n",
      "|model-vegas| >= 3: win 44.93% out of 138 games, profit -19.64 units\n",
      "|model-vegas| >= 4: win 43.33% out of 60 games, profit -10.36 units\n",
      "|model-vegas| >= 5: win 45.45% out of 33 games, profit -4.36 units\n",
      "|model-vegas| >= 6: win 42.86% out of 14 games, profit -2.55 units\n",
      "|model-vegas| >= 7: win 45.45% out of 11 games, profit -1.45 units\n",
      "|model-vegas| >= 8: win 57.14% out of 7 games, profit 0.64 units\n",
      "|model-vegas| >= 9: win 40.00% out of 5 games, profit -1.18 units\n",
      "|model-vegas| >= 10: win 25.00% out of 4 games, profit -2.09 units\n",
      "|model-vegas| >= 11: win 50.00% out of 2 games, profit -0.09 units\n",
      "|model-vegas| >= 12: win 50.00% out of 2 games, profit -0.09 units\n",
      "|model-vegas| >= 13: win 50.00% out of 2 games, profit -0.09 units\n",
      "|model-vegas| >= 14: win 100.00% out of 1 games, profit 0.91 units\n",
      "|model-vegas| >= 15: win 100.00% out of 1 games, profit 0.91 units\n",
      "\n",
      "Results by week:\n",
      "Week 1: win 34.00% out of 50 games, profit -17.55 units\n",
      "Week 2: win 56.52% out of 46 games, profit 3.64 units\n",
      "Week 3: win 38.00% out of 50 games, profit -13.73 units\n",
      "Week 4: win 45.00% out of 60 games, profit -8.45 units\n",
      "Week 5: win 48.21% out of 56 games, profit -4.45 units\n",
      "Week 6: win 50.88% out of 57 games, profit -1.64 units\n",
      "Week 7: win 60.00% out of 50 games, profit 7.27 units\n",
      "Week 8: win 64.58% out of 48 games, profit 11.18 units\n",
      "Week 9: win 38.30% out of 47 games, profit -12.64 units\n",
      "Week 10: win 56.67% out of 60 games, profit 4.91 units\n",
      "Week 11: win 41.94% out of 62 games, profit -12.36 units\n",
      "Week 12: win 47.54% out of 61 games, profit -5.64 units\n",
      "Week 13: win 49.21% out of 63 games, profit -3.82 units\n",
      "Week 14: win 54.55% out of 11 games, profit 0.45 units\n",
      "\n",
      "Results by conference:\n",
      "Power 5 v. Power 5 games: win 54.30% out of 302 games, profit 11.09 units\n",
      "non-Power 5 vs non-Power 5 games: win 46.35% out of 315 games, profit -36.27 units\n",
      "SEC conference games: win 50.88% out of 57 games, profit -1.64 units\n",
      "SEC non-conference games: win 34.15% out of 41 games, profit -14.27 units\n",
      "Big Ten conference games: win 59.02% out of 61 games, profit 7.73 units\n",
      "Big Ten non-conference games: win 48.48% out of 33 games, profit -2.45 units\n",
      "Big 12 conference games: win 58.70% out of 46 games, profit 5.55 units\n",
      "Big 12 non-conference games: win 45.45% out of 22 games, profit -2.91 units\n",
      "ACC conference games: win 57.41% out of 54 games, profit 5.18 units\n",
      "ACC non-conference games: win 31.71% out of 41 games, profit -16.18 units\n",
      "Sun Belt conference games: win 53.57% out of 56 games, profit 1.27 units\n",
      "Sun Belt non-conference games: win 42.50% out of 40 games, profit -7.55 units\n",
      "Mountain West conference games: win 43.75% out of 48 games, profit -7.91 units\n",
      "Mountain West non-conference games: win 41.67% out of 36 games, profit -7.36 units\n",
      "American Athletic conference games: win 46.67% out of 45 games, profit -4.91 units\n",
      "American Athletic non-conference games: win 50.00% out of 34 games, profit -1.55 units\n",
      "Mid-American conference games: win 37.50% out of 48 games, profit -13.64 units\n",
      "Mid-American non-conference games: win 51.43% out of 35 games, profit -0.64 units\n",
      "Conference USA conference games: win 44.19% out of 43 games, profit -6.73 units\n",
      "Conference USA non-conference games: win 34.29% out of 35 games, profit -12.09 units\n",
      "FBS Independents conference games: win 44.44% out of 9 games, profit -1.36 units\n",
      "FBS Independents non-conference games: win 49.12% out of 57 games, profit -3.55 units\n"
     ]
    }
   ],
   "source": [
    "# y_pred = model.predict(X_test_scaled)\n",
    "y_pred = prediction(xgb_model, dtest)\n",
    "\n",
    "print(f\"RMSE of Model on test data: {mean_squared_error(y_test, y_pred)**0.5}\")\n",
    "print(f\"RMSE of Vegas on test data: {mean_squared_error(y_test, X_test['spread'])**0.5}\")\n",
    "print(f\"MAE of Model on test data: {mean_absolute_error(y_test, y_pred)}\")\n",
    "print(f\"MAE of Vegas on test data: {mean_absolute_error(y_test, X_test['spread'])}\\n\")\n",
    "\n",
    "spread_values = X_test['spread'].values\n",
    "model_vs_vegas_results = np.where(y_test < spread_values, y_pred < spread_values, y_pred > spread_values)\n",
    "\n",
    "# X_test.insert(X_test.columns.get_loc('spread') + 1, 'predicted', y_pred)\n",
    "# X_test.insert(X_test.columns.get_loc('predicted') + 1, 'margin', y_test)\n",
    "# X_test.insert(X_test.columns.get_loc('predicted') + 1, 'model_win',  np.where(model_vs_vegas_results, 'yes', 'no'))\n",
    "\n",
    "def profit(unit, num_wins, num_bets, odds):\n",
    "    return unit * (-num_bets + num_wins * (1 + 100/(-odds)))\n",
    "\n",
    "print(\"Results by difference between model and Vegas:\")\n",
    "max_diff = int(np.max(np.abs(spread_values - y_pred)))\n",
    "for spread_difference in range(0,max_diff):\n",
    "    selected_indices = np.abs(spread_values - y_pred) >= spread_difference\n",
    "    selected_games = X_test[selected_indices]\n",
    "    selected_games_spreads = selected_games['spread'].values\n",
    "    y_pred_selected_games = y_pred[selected_indices]\n",
    "    y_test_selected_games = y_test[selected_indices]\n",
    "    model_vs_vegas_confident_results = np.where(y_test_selected_games < selected_games_spreads, y_pred_selected_games < selected_games_spreads, y_pred_selected_games > selected_games_spreads)\n",
    "    print(f\"|model-vegas| >= {spread_difference}: win {(model_vs_vegas_confident_results.mean()) * 100:.2f}% out of {len(selected_games)} games, profit {profit(1, sum(model_vs_vegas_confident_results), len(model_vs_vegas_confident_results), -110):.2f} units\")\n",
    "\n",
    "print(\"\\nResults by week:\")\n",
    "week_values = data.query(\"year >= 2022\")['week'].values\n",
    "for week in range(int(np.min(week_values)),int(np.max(week_values))):\n",
    "    selected_indices = week_values == week\n",
    "    selected_games = X_test[selected_indices]\n",
    "    selected_games_spreads = selected_games['spread'].values\n",
    "    y_pred_selected_games = y_pred[selected_indices]\n",
    "    y_test_selected_games = y_test[selected_indices]\n",
    "    model_vs_vegas_confident_results = np.where(y_test_selected_games < selected_games_spreads, y_pred_selected_games < selected_games_spreads, y_pred_selected_games > selected_games_spreads)\n",
    "    print(f\"Week {week}: win {(model_vs_vegas_confident_results.mean()) * 100:.2f}% out of {len(selected_games)} games, profit {profit(1, sum(model_vs_vegas_confident_results), len(model_vs_vegas_confident_results), -110):.2f} units\")\n",
    "\n",
    "\n",
    "conferences = ['SEC', 'Big Ten', 'Big 12', 'ACC', 'Sun Belt', 'Mountain West',  'American Athletic', 'Mid-American', 'Conference USA', 'FBS Independents']\n",
    "p5_conferences = ['Big Ten', 'SEC', 'ACC', 'Big 12', 'Pac-12']\n",
    "\n",
    "print(\"\\nResults by conference:\")\n",
    "p5_indices = (X_test['home_conference'].isin(p5_conferences)) & (X_test['away_conference'].isin(p5_conferences))\n",
    "p5_games = X_test[p5_indices]\n",
    "p5_spreads = p5_games['spread'].values\n",
    "p5_y_pred = y_pred[p5_indices]\n",
    "p5_y_test = y_test[p5_indices]\n",
    "p5_model_vs_vegas_results = np.where(p5_y_test < p5_spreads, p5_y_pred < p5_spreads, p5_y_pred > p5_spreads)\n",
    "\n",
    "non_p5_indices = (~X_test['home_conference'].isin(p5_conferences)) & (~X_test['away_conference'].isin(p5_conferences))\n",
    "non_p5_games = X_test[non_p5_indices]\n",
    "non_p5_spreads = non_p5_games['spread'].values\n",
    "non_p5_y_pred = y_pred[non_p5_indices]\n",
    "non_p5_y_test = y_test[non_p5_indices]\n",
    "non_p5_model_vs_vegas_results = np.where(non_p5_y_test < non_p5_spreads, non_p5_y_pred < non_p5_spreads, non_p5_y_pred > non_p5_spreads)\n",
    "\n",
    "print(f\"Power 5 v. Power 5 games: win {(p5_model_vs_vegas_results.mean()) * 100:.2f}% out of {len(p5_games)} games, profit {profit(1, sum(p5_model_vs_vegas_results), len(p5_model_vs_vegas_results), -110):.2f} units\")\n",
    "print(f\"non-Power 5 vs non-Power 5 games: win {(non_p5_model_vs_vegas_results.mean()) * 100:.2f}% out of {len(non_p5_games)} games, profit {profit(1, sum(non_p5_model_vs_vegas_results), len(non_p5_model_vs_vegas_results), -110):.2f} units\")\n",
    "for conference in conferences:\n",
    "    same_conf_indices = (X_test['home_conference'] == conference) & (X_test['away_conference'] == conference)\n",
    "    same_conf_games = X_test[same_conf_indices]\n",
    "    same_conf_spreads = same_conf_games['spread'].values\n",
    "    same_conf_y_pred = y_pred[same_conf_indices]\n",
    "    same_conf_y_test = y_test[same_conf_indices]\n",
    "    same_conf_model_vs_vegas_results = np.where(same_conf_y_test < same_conf_spreads, same_conf_y_pred < same_conf_spreads, same_conf_y_pred > same_conf_spreads)\n",
    "\n",
    "    diff_conf_indices = ((X_test['home_conference'] == conference) & (X_test['away_conference'] != conference)) | ((X_test['home_conference'] != conference) & (X_test['away_conference'] == conference))\n",
    "    diff_conf_games = X_test[diff_conf_indices]\n",
    "    diff_conf_spreads = diff_conf_games['spread'].values\n",
    "    diff_conf_y_pred = y_pred[diff_conf_indices]\n",
    "    diff_conf_y_test = y_test[diff_conf_indices]\n",
    "    diff_conf_model_vs_vegas_results = np.where(diff_conf_y_test < diff_conf_spreads, diff_conf_y_pred < diff_conf_spreads, diff_conf_y_pred > diff_conf_spreads)\n",
    "\n",
    "    print(f\"{conference} conference games: win {(same_conf_model_vs_vegas_results.mean()) * 100:.2f}% out of {len(same_conf_games)} games, profit {profit(1, sum(same_conf_model_vs_vegas_results), len(same_conf_model_vs_vegas_results), -110):.2f} units\")\n",
    "    print(f\"{conference} non-conference games: win {(diff_conf_model_vs_vegas_results.mean()) * 100:.2f}% out of {len(diff_conf_games)} games, profit {profit(1, sum(diff_conf_model_vs_vegas_results), len(diff_conf_model_vs_vegas_results), -110):.2f} units\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
